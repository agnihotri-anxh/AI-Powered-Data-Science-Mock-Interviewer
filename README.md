# AI-Powered Data Science Mock Interviewer

An intelligent mock interview system that generates data science questions from "The Hundred-Page Machine Learning Book" and evaluates your responses using AI.
<img width="1829" height="894" alt="Screenshot 2025-09-22 161455" src="https://github.com/user-attachments/assets/413a68cd-5d9f-4bc9-98c1-292d2e008a36" />
<img width="1810" height="884" alt="Screenshot 2025-09-22 162159" src="https://github.com/user-attachments/assets/1f1d646a-d17d-4f8c-bbfe-ba5ffd2f6535" />
<img width="1522" height="865" alt="Screenshot 2025-09-22 162731" src="https://github.com/user-attachments/assets/0e65c8f6-771e-4079-93c1-d95780557a03" />

## Features

- ğŸ“š **Knowledge Base**: Extracts concepts from "The Hundred-Page Machine Learning Book"
- ğŸ¤– **AI-Powered Questions**: Generates contextual questions using extracted knowledge
- ğŸ¯ **Smart Evaluation**: AI evaluates responses with detailed feedback
- ğŸ” **Accounts**: Signup/login backed by MongoDB
- ğŸµ **Audio Support**: Text-to-speech for questions via ElevenLabs

## Prerequisites

- Python 3.9+ (tested on 3.10/3.11)
- A running MongoDB instance and connection string (`MONGO_URI`)
- API keys: Groq (`GROQ_API_KEY`) and ElevenLabs (`ELEVENLABS_API_KEY`)
- The PDF file: `The Hundred-Page Machine Learning Book.pdf` in the project root

## Quick Start

### 1) Install dependencies

```bash
pip install -r requirements.txt
```

### 2) Configure environment variables

Create a `.env` file in the project root. On Windows PowerShell:

```powershell
Copy-Item env_example.txt .env
```

Then edit `.env` and set at least:

- `GROQ_API_KEY=<your_groq_api_key>`
- `ELEVENLABS_API_KEY=<your_elevenlabs_api_key>`
- `MONGO_URI=<your_mongodb_connection_string>`
- `SECRET_KEY=<any_random_secret_string>`
- Optional: `MONGODB_DB` (default: `AI-Interviewer-DB`), `MONGODB_USERS_COLLECTION` (default: `users`)

### 3) Build the knowledge base

Make sure the PDF is present as `The Hundred-Page Machine Learning Book.pdf` and run:

```bash
python run_extraction.py
```

This will create `knowledge_base/index.faiss` and `knowledge_base/index.pkl`.

### 4) Start the app

```bash
python app.py
```

Open your browser at `http://127.0.0.1:5000`.

## How it works

- `Data_Ingestion.py`: Extracts text from the PDF and builds a FAISS vector store using sentence-transformers.
- `app.py`: Flask app that
  - serves pages (`landing_page.html`, `login.html`, `signup.html`, `index.html`),
  - uses LangChain + Groq to generate questions from the knowledge base,
  - checks answer relevance and composes a final evaluation after 10 Q&A pairs,
  - uses ElevenLabs to synthesize audio for questions at `/synthesize`.

### Routes

- `GET /` â†’ Landing page
- `GET|POST /login`, `GET|POST /signup` â†’ Authentication
- `GET /interview` â†’ Interview UI (requires login)
- `POST /ask` â†’ Generate a question for a given topic
- `POST /submit_answer` â†’ Submit answer, get follow-up or final feedback
- `POST /synthesize` â†’ TTS audio for given text (requires login)

## Project structure

```
AI Powered Data Scince Interviewer/
â”œâ”€â”€ app.py                         # Flask application
â”œâ”€â”€ Data_Ingestion.py              # PDF ingestion and vector store builder
â”œâ”€â”€ run_extraction.py              # Builds the knowledge base
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ env_example.txt                # .env template
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html                 # Interview UI
â”‚   â”œâ”€â”€ landing_page.html          # Landing page
â”‚   â”œâ”€â”€ login.html                 # Login page
â”‚   â””â”€â”€ signup.html                # Signup page
â”œâ”€â”€ knowledge_base/
â”‚   â”œâ”€â”€ index.faiss                # FAISS index
â”‚   â””â”€â”€ index.pkl                  # Embeddings/metadata
â””â”€â”€ The Hundred-Page Machine Learning Book.pdf
```

## Usage

1. Sign up at `/signup` and then log in at `/login`.
2. Go to `/interview` and enter a data science topic (e.g., "cross validation").
3. Answer each question. After 10 questions, youâ€™ll receive a detailed final evaluation.
4. Use the audio button (if available) to hear questions synthesized via ElevenLabs.

## Troubleshooting

- **Knowledge base not found**: Run `python run_extraction.py` and ensure the PDF filename matches exactly.
- **MongoDB connection failed**: Verify `MONGO_URI` and that your database allows connections from your machine.
- **Missing API keys**: Ensure `GROQ_API_KEY` and `ELEVENLABS_API_KEY` are present in `.env`.
- **Port in use**: Change the port in `app.py` (default 5000).
- **Windows venv**: If using a venv, activate it with `./venv/Scripts/Activate.ps1` before installing/running.

## Technology stack

- **Backend**: Python, Flask
- **AI Orchestration**: LangChain
- **LLM**: Groq (`mixtral-8x7b-32768`)
- **Embeddings & Vector Search**: sentence-transformers, FAISS
- **Auth & Data**: Flask-Login session + MongoDB (`flask-pymongo`)
- **TTS**: ElevenLabs
- **PDF Processing**: PyPDF / related utilities

## License

This project is for educational purposes. Please respect the copyright of
"The Hundred-Page Machine Learning Book".
Use it inside an itemize list. Example second bullet:
```latex
\begin{itemize}
  \item Built mock interviewer leveraging RAG over ML book content
  \item Implemented FAISS-based retrieval with Groq LLM; added relevance checks and final scoring
\end{itemize}
```### LaTeX snippet for your resume

```latex
% Projects section entry (works in most resume templates)
\section{Projects}
\noindent\textbf{AI-Powered Data Science Mock Interviewer} \hfill \textit{Python, Flask, LangChain, Groq, FAISS, MongoDB, ElevenLabs} \\
\href{https://github.com/agnihotri-anxh/AI-Powered-Data-Science-Mock-Interviewer}{github.com/agnihotri-anxh/AI-Powered-Data-Science-Mock-Interviewer} \hfill \textit{2025}
\begin{itemize}\itemsep 0.2em
  \item Built a mock interviewer that generates contextual questions from â€œThe Hundred-Page Machine Learning Bookâ€ and evaluates answers with LLMs.
  \item Implemented retrieval-augmented generation using sentence-transformer embeddings with FAISS and a Groq-hosted model for question generation.
  \item Added relevance checking and a final comprehensive evaluation after 10 Q\&A pairs (summary, strengths, improvements, score).
  \item Developed user auth with MongoDB (signup/login, session management) and input validation for topic/answer quality.
  \item Integrated ElevenLabs TTS to synthesize questions; created a clean Tailwind UI for interview flow.
  \item Automated PDF ingestion pipeline to build a reusable vector knowledge base.
\end{itemize}
```

If your template uses a â€œWork/Projectâ€ entry format with dates/location, you can wrap it like:

```latex
\textbf{AI-Powered Data Science Mock Interviewer} \hfill \textit{Remote \quad 2025}\\
\textit{Python, Flask, LangChain, Groq, FAISS, MongoDB, ElevenLabs} \hfill
\href{https://github.com/agnihotri-anxh/AI-Powered-Data-Science-Mock-Interviewer}{GitHub}
\begin{itemize}\itemsep 0.2em
  \item Built RAG-driven interviewer; generated questions from curated ML book context; delivered final scored feedback.
  \item Implemented FAISS vector store, relevance checks, MongoDB auth, and TTS for accessibility.
\end{itemize}
```